{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Jalon3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPvvatxeUU0smtTMGzoVCzA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pKJDuwEXPpl","executionInfo":{"status":"ok","timestamp":1641908370896,"user_tz":-60,"elapsed":21359,"user":{"displayName":"Emonet Louis-Marie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrbuEVeoLaAJZImlLzNHs8w817M4CMwjFHfvvKgA=s64","userId":"05752284584494513720"}},"outputId":"c4310c2f-4acd-4fb1-aa59-ae3b7d177c59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pip install -U textblob\n","!pip install contractions"],"metadata":{"id":"I7tqujJzST5t"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Foh88qwMSBt-"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from textblob import TextBlob\n","import contractions\n","import pickle\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"code","source":["def prediction(text):\n","  if TextBlob(text).sentiment.polarity >= 0:\n","    return \"Cet avis n'apparait pas comme negatif\"\n","  else:\n","    # tokenize\n","    text = contractions.fix(text).lower()\n","    tokenizer = RegexpTokenizer(r\"\\w+\")\n","    text = tokenizer.tokenize(text)\n","    # print(\"Tokens:\",text)\n","\n","    # remove stops words\n","    stop_words = set(stopwords.words('english'))\n","    text = [word for word in text if word not in stop_words]\n","    # print(\"Stop words:\",text)\n","\n","    # lemmatize\n","    lemmatizer = WordNetLemmatizer()\n","    token_tag = nltk.pos_tag(text)\n","    lemm_text = []              \n","    for word, tag in token_tag :                          \n","      if tag.startswith('J'):\n","        lemm_text.append(lemmatizer.lemmatize(word,'a'))\n","      elif tag.startswith('V'):\n","        lemm_text.append(lemmatizer.lemmatize(word,'v'))\n","      elif tag.startswith('N'):\n","        lemm_text.append(lemmatizer.lemmatize(word,'n'))\n","      elif tag == 'PRP' :\n","        lemm_text.append(word)\n","      elif tag.startswith('R'):\n","        lemm_text.append(lemmatizer.lemmatize(word,'r'))\n","      else :\n","        lemm_text.append(lemmatizer.lemmatize(word)) \n","    # print(\"Lemmatized:\",lemm_text)\n","\n","\n","    # join\n","    clean_text = ' '.join(lemm_text)\n","    # print(\"Join:\", clean_text )\n","\n","    # vectorize\n","    with open('drive/MyDrive/vectoriseur', 'rb') as file:\n","      vectorizer = pickle.load(file)\n","    X = vectorizer.transform([clean_text])\n","    # print(\"Vectorised :\", X)\n","\n","    # predict\n","    with open('drive/MyDrive/model', 'rb') as file:\n","      model = pickle.load(file)\n","    W = model.transform(X)\n","    # print(\"Matrice topic:\", W.argmax())\n","\n","    # topic\n","    topic = {'topic1':'ACCUEIL ET SERVICE', 'topic2':'NOURRITURE ASIATQUE MAUVAISE ', 'topic3':\"TEMPS D'ATTENTE ET PIZZA FROIDE OU TROP CUITE\", 'topic4':'MAUVAISE EXPERIENCE AVEC LE PESONNEL ', \n","            'topic5':'PROBLEME BURGER (ERREUR COMMANDE, PRIX ELEVE, ETC)', 'topic6':\"TEMPS D'ATTENTE TROP LONG\", 'topic7':'PROBLEME QUALITE BURGER', 'topic8':'TRES MAUVAIS SERVICE CLIENT', \n","            'topic9':'PROBLEME DE POULET', 'topic10':'BAR MAUVAIS EXPEIENCE AVEC LE PERSONNEL', 'topic11':'CLIENT DECU, NE REVIENDRA PAS', 'topic12':'NOURRITURE JAPONNAISE DECEVANTE', \n","            'topic13':'MAUVAIS SANDWICH', 'topic14':'EXPERIENCE MEDIOCRE, PRIX LEGEREMENT TROP ELEVES', 'topic15':'PROBLEME DANS LA COMMANDE' }\n","\n","    # print(\"Topic: \", list(topic.values())[W.argmax()])\n","    topics = []\n","    results = np.argsort(W)\n","    print(results)\n","\n","    for index in results[0][-n:]:\n","        print(type(index), index)\n","        topics.append(list(topic.values())[int(index)])\n","\n","    # result_sorted = np.argsort(results)\n","    # result_sorted = topic.values().sort()\n","    # topics = result_sorted[:n]\n","    topics.reverse()\n","    return topics\n","    # return list(topic.values())[W.argmax()]\n"],"metadata":{"id":"usRr1d4vS43d"},"execution_count":null,"outputs":[]}]}